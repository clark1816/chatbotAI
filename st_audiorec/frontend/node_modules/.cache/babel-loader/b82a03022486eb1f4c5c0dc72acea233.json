{"ast":null,"code":"// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { clampRange } from '../util/vector';\nimport { DataType } from '../type';\nimport { selectChunkArgs } from '../util/args';\nimport { AbstractVector, Vector } from '../vector';\n/** @ignore */\n\nexport class Chunked extends AbstractVector {\n  constructor(type) {\n    let chunks = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n    let offsets = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : calculateOffsets(chunks);\n    super();\n    this._nullCount = -1;\n    this._type = type;\n    this._chunks = chunks;\n    this._chunkOffsets = offsets;\n    this._length = offsets[offsets.length - 1];\n    this._numChildren = (this._type.children || []).length;\n  }\n  /** @nocollapse */\n\n\n  static flatten() {\n    for (var _len = arguments.length, vectors = new Array(_len), _key = 0; _key < _len; _key++) {\n      vectors[_key] = arguments[_key];\n    }\n\n    return selectChunkArgs(Vector, vectors);\n  }\n  /** @nocollapse */\n\n\n  static concat() {\n    const chunks = Chunked.flatten(...arguments);\n    return new Chunked(chunks[0].type, chunks);\n  }\n\n  get type() {\n    return this._type;\n  }\n\n  get length() {\n    return this._length;\n  }\n\n  get chunks() {\n    return this._chunks;\n  }\n\n  get typeId() {\n    return this._type.typeId;\n  }\n\n  get VectorName() {\n    return `Chunked<${this._type}>`;\n  }\n\n  get data() {\n    return this._chunks[0] ? this._chunks[0].data : null;\n  }\n\n  get ArrayType() {\n    return this._type.ArrayType;\n  }\n\n  get numChildren() {\n    return this._numChildren;\n  }\n\n  get stride() {\n    return this._chunks[0] ? this._chunks[0].stride : 1;\n  }\n\n  get byteLength() {\n    return this._chunks.reduce((byteLength, chunk) => byteLength + chunk.byteLength, 0);\n  }\n\n  get nullCount() {\n    let nullCount = this._nullCount;\n\n    if (nullCount < 0) {\n      this._nullCount = nullCount = this._chunks.reduce((x, _ref) => {\n        let {\n          nullCount\n        } = _ref;\n        return x + nullCount;\n      }, 0);\n    }\n\n    return nullCount;\n  }\n\n  get indices() {\n    if (DataType.isDictionary(this._type)) {\n      if (!this._indices) {\n        const chunks = this._chunks;\n        this._indices = chunks.length === 1 ? chunks[0].indices : Chunked.concat(...chunks.map(x => x.indices));\n      }\n\n      return this._indices;\n    }\n\n    return null;\n  }\n\n  get dictionary() {\n    if (DataType.isDictionary(this._type)) {\n      return this._chunks[this._chunks.length - 1].data.dictionary;\n    }\n\n    return null;\n  }\n\n  *[Symbol.iterator]() {\n    for (const chunk of this._chunks) {\n      yield* chunk;\n    }\n  }\n\n  clone() {\n    let chunks = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this._chunks;\n    return new Chunked(this._type, chunks);\n  }\n\n  concat() {\n    for (var _len2 = arguments.length, others = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n      others[_key2] = arguments[_key2];\n    }\n\n    return this.clone(Chunked.flatten(this, ...others));\n  }\n\n  slice(begin, end) {\n    return clampRange(this, begin, end, this._sliceInternal);\n  }\n\n  getChildAt(index) {\n    if (index < 0 || index >= this._numChildren) {\n      return null;\n    }\n\n    let columns = this._children || (this._children = []);\n    let child, field, chunks;\n\n    if (child = columns[index]) {\n      return child;\n    }\n\n    if (field = (this._type.children || [])[index]) {\n      chunks = this._chunks.map(vector => vector.getChildAt(index)).filter(vec => vec != null);\n\n      if (chunks.length > 0) {\n        return columns[index] = new Chunked(field.type, chunks);\n      }\n    }\n\n    return null;\n  }\n\n  search(index, then) {\n    let idx = index; // binary search to find the child vector and value indices\n\n    let offsets = this._chunkOffsets,\n        rhs = offsets.length - 1; // return early if out of bounds, or if there's just one child\n\n    if (idx < 0) {\n      return null;\n    }\n\n    if (idx >= offsets[rhs]) {\n      return null;\n    }\n\n    if (rhs <= 1) {\n      return then ? then(this, 0, idx) : [0, idx];\n    }\n\n    let lhs = 0,\n        pos = 0,\n        mid = 0;\n\n    do {\n      if (lhs + 1 === rhs) {\n        return then ? then(this, lhs, idx - pos) : [lhs, idx - pos];\n      }\n\n      mid = lhs + (rhs - lhs) / 2 | 0;\n      idx >= offsets[mid] ? lhs = mid : rhs = mid;\n    } while (idx < offsets[rhs] && idx >= (pos = offsets[lhs]));\n\n    return null;\n  }\n\n  isValid(index) {\n    return !!this.search(index, this.isValidInternal);\n  }\n\n  get(index) {\n    return this.search(index, this.getInternal);\n  }\n\n  set(index, value) {\n    this.search(index, (_ref2, i, j) => {\n      let {\n        chunks\n      } = _ref2;\n      return chunks[i].set(j, value);\n    });\n  }\n\n  indexOf(element, offset) {\n    if (offset && typeof offset === 'number') {\n      return this.search(offset, (self, i, j) => this.indexOfInternal(self, i, j, element));\n    }\n\n    return this.indexOfInternal(this, 0, Math.max(0, offset || 0), element);\n  }\n\n  toArray() {\n    const {\n      chunks\n    } = this;\n    const n = chunks.length;\n    let ArrayType = this._type.ArrayType;\n\n    if (n <= 0) {\n      return new ArrayType(0);\n    }\n\n    if (n <= 1) {\n      return chunks[0].toArray();\n    }\n\n    let len = 0,\n        src = new Array(n);\n\n    for (let i = -1; ++i < n;) {\n      len += (src[i] = chunks[i].toArray()).length;\n    }\n\n    if (ArrayType !== src[0].constructor) {\n      ArrayType = src[0].constructor;\n    }\n\n    let dst = new ArrayType(len);\n    let set = ArrayType === Array ? arraySet : typedSet;\n\n    for (let i = -1, idx = 0; ++i < n;) {\n      idx = set(src[i], dst, idx);\n    }\n\n    return dst;\n  }\n\n  getInternal(_ref3, i, j) {\n    let {\n      _chunks\n    } = _ref3;\n    return _chunks[i].get(j);\n  }\n\n  isValidInternal(_ref4, i, j) {\n    let {\n      _chunks\n    } = _ref4;\n    return _chunks[i].isValid(j);\n  }\n\n  indexOfInternal(_ref5, chunkIndex, fromIndex, element) {\n    let {\n      _chunks\n    } = _ref5;\n    let i = chunkIndex - 1,\n        n = _chunks.length;\n    let start = fromIndex,\n        offset = 0,\n        found = -1;\n\n    while (++i < n) {\n      if (~(found = _chunks[i].indexOf(element, start))) {\n        return offset + found;\n      }\n\n      start = 0;\n      offset += _chunks[i].length;\n    }\n\n    return -1;\n  }\n\n  _sliceInternal(self, begin, end) {\n    const slices = [];\n    const {\n      chunks,\n      _chunkOffsets: chunkOffsets\n    } = self;\n\n    for (let i = -1, n = chunks.length; ++i < n;) {\n      const chunk = chunks[i];\n      const chunkLength = chunk.length;\n      const chunkOffset = chunkOffsets[i]; // If the child is to the right of the slice boundary, we can stop\n\n      if (chunkOffset >= end) {\n        break;\n      } // If the child is to the left of of the slice boundary, exclude\n\n\n      if (begin >= chunkOffset + chunkLength) {\n        continue;\n      } // If the child is between both left and right boundaries, include w/o slicing\n\n\n      if (chunkOffset >= begin && chunkOffset + chunkLength <= end) {\n        slices.push(chunk);\n        continue;\n      } // If the child overlaps one of the slice boundaries, include that slice\n\n\n      const from = Math.max(0, begin - chunkOffset);\n      const to = Math.min(end - chunkOffset, chunkLength);\n      slices.push(chunk.slice(from, to));\n    }\n\n    return self.clone(slices);\n  }\n\n}\n/** @ignore */\n\nfunction calculateOffsets(vectors) {\n  let offsets = new Uint32Array((vectors || []).length + 1);\n  let offset = offsets[0] = 0,\n      length = offsets.length;\n\n  for (let index = 0; ++index < length;) {\n    offsets[index] = offset += vectors[index - 1].length;\n  }\n\n  return offsets;\n}\n/** @ignore */\n\n\nconst typedSet = (src, dst, offset) => {\n  dst.set(src, offset);\n  return offset + src.length;\n};\n/** @ignore */\n\n\nconst arraySet = (src, dst, offset) => {\n  let idx = offset;\n\n  for (let i = -1, n = src.length; ++i < n;) {\n    dst[idx++] = src[i];\n  }\n\n  return idx;\n};","map":{"version":3,"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA,SAASA,UAAT,QAA2B,gBAA3B;AACA,SAASC,QAAT,QAAqC,SAArC;AACA,SAASC,eAAT,QAAgC,cAAhC;AAEA,SAASC,cAAT,EAAyBC,MAAzB,QAAuC,WAAvC;AAWA;;AACA,OAAM,MAAOC,OAAP,SACMF,cADN,CACuB;AAwBzBG,cAAYC,IAAZ,EAAiF;AAAA,QAA5DC,MAA4D,uEAAtC,EAAsC;AAAA,QAAlCC,OAAkC,uEAAxBC,gBAAgB,CAACF,MAAD,CAAQ;AAC7E;AAJM,sBAAqB,CAAC,CAAtB;AAKN,SAAKG,KAAL,GAAaJ,IAAb;AACA,SAAKK,OAAL,GAAeJ,MAAf;AACA,SAAKK,aAAL,GAAqBJ,OAArB;AACA,SAAKK,OAAL,GAAeL,OAAO,CAACA,OAAO,CAACM,MAAR,GAAiB,CAAlB,CAAtB;AACA,SAAKC,YAAL,GAAoB,CAAC,KAAKL,KAAL,CAAWM,QAAX,IAAuB,EAAxB,EAA4BF,MAAhD;AACH;AA1BD;;;AACqB,SAAPG,OAAO,GAA4D;AAAA,sCAApCC,OAAoC;AAApCA,aAAoC;AAAA;;AAC7E,WAAOjB,eAAe,CAAYE,MAAZ,EAAoBe,OAApB,CAAtB;AACH;AAED;;;AACoB,SAANC,MAAM,GAA4D;AAC5E,UAAMZ,MAAM,GAAGH,OAAO,CAACa,OAAR,CAAmB,YAAnB,CAAf;AACA,WAAO,IAAIb,OAAJ,CAAeG,MAAM,CAAC,CAAD,CAAN,CAAUD,IAAzB,EAA+BC,MAA/B,CAAP;AACH;;AAmBc,MAAJD,IAAI;AAAK,WAAO,KAAKI,KAAZ;AAAoB;;AACvB,MAANI,MAAM;AAAK,WAAO,KAAKD,OAAZ;AAAsB;;AAC3B,MAANN,MAAM;AAAK,WAAO,KAAKI,OAAZ;AAAsB;;AAC3B,MAANS,MAAM;AAAiB,WAAO,KAAKV,KAAL,CAAWU,MAAlB;AAA2B;;AACxC,MAAVC,UAAU;AAAK,WAAO,WAAW,KAAKX,KAAK,GAA5B;AAAkC;;AAC7C,MAAJY,IAAI;AACX,WAAO,KAAKX,OAAL,CAAa,CAAb,IAAkB,KAAKA,OAAL,CAAa,CAAb,EAAgBW,IAAlC,GAA+C,IAAtD;AACH;;AAEmB,MAATC,SAAS;AAAK,WAAO,KAAKb,KAAL,CAAWa,SAAlB;AAA8B;;AACjC,MAAXC,WAAW;AAAK,WAAO,KAAKT,YAAZ;AAA2B;;AACrC,MAANU,MAAM;AAAK,WAAO,KAAKd,OAAL,CAAa,CAAb,IAAkB,KAAKA,OAAL,CAAa,CAAb,EAAgBc,MAAlC,GAA2C,CAAlD;AAAsD;;AACvD,MAAVC,UAAU;AACjB,WAAO,KAAKf,OAAL,CAAagB,MAAb,CAAoB,CAACD,UAAD,EAAaE,KAAb,KAAuBF,UAAU,GAAGE,KAAK,CAACF,UAA9D,EAA0E,CAA1E,CAAP;AACH;;AACmB,MAATG,SAAS;AAChB,QAAIA,SAAS,GAAG,KAAKC,UAArB;;AACA,QAAID,SAAS,GAAG,CAAhB,EAAmB;AACf,WAAKC,UAAL,GAAkBD,SAAS,GAAG,KAAKlB,OAAL,CAAagB,MAAb,CAAoB,CAACI,CAAD;AAAA,YAAI;AAAEF;AAAF,SAAJ;AAAA,eAAsBE,CAAC,GAAGF,SAA1B;AAAA,OAApB,EAAyD,CAAzD,CAA9B;AACH;;AACD,WAAOA,SAAP;AACH;;AAGiB,MAAPG,OAAO;AACd,QAAIhC,QAAQ,CAACiC,YAAT,CAAsB,KAAKvB,KAA3B,CAAJ,EAAuC;AACnC,UAAI,CAAC,KAAKwB,QAAV,EAAoB;AAChB,cAAM3B,MAAM,GAAU,KAAKI,OAA3B;AACA,aAAKuB,QAAL,GAAiB3B,MAAM,CAACO,MAAP,KAAkB,CAAlB,GACXP,MAAM,CAAC,CAAD,CAAN,CAAUyB,OADC,GAEX5B,OAAO,CAACe,MAAR,CAAe,GAAGZ,MAAM,CAAC4B,GAAP,CAAYJ,CAAD,IAAOA,CAAC,CAACC,OAApB,CAAlB,CAFN;AAGH;;AACD,aAAO,KAAKE,QAAZ;AACH;;AACD,WAAO,IAAP;AACH;;AACoB,MAAVE,UAAU;AACjB,QAAIpC,QAAQ,CAACiC,YAAT,CAAsB,KAAKvB,KAA3B,CAAJ,EAAuC;AACnC,aAAO,KAAKC,OAAL,CAAa,KAAKA,OAAL,CAAaG,MAAb,GAAsB,CAAnC,EAAsCQ,IAAtC,CAA2Cc,UAAlD;AACH;;AACD,WAAO,IAAP;AACH;;AAEuB,IAAfC,MAAM,CAACC,QAAQ,IAAC;AACrB,SAAK,MAAMV,KAAX,IAAoB,KAAKjB,OAAzB,EAAkC;AAC9B,aAAOiB,KAAP;AACH;AACJ;;AAEMW,OAAK,GAAsB;AAAA,QAArBhC,MAAqB,uEAAZ,KAAKI,OAAO;AAC9B,WAAO,IAAIP,OAAJ,CAAY,KAAKM,KAAjB,EAAwBH,MAAxB,CAAP;AACH;;AAEMY,QAAM,GAAuB;AAAA,uCAAnBqB,MAAmB;AAAnBA,YAAmB;AAAA;;AAChC,WAAO,KAAKD,KAAL,CAAWnC,OAAO,CAACa,OAAR,CAAgB,IAAhB,EAAsB,GAAGuB,MAAzB,CAAX,CAAP;AACH;;AAEMC,OAAK,CAACC,KAAD,EAAiBC,GAAjB,EAA6B;AACrC,WAAO5C,UAAU,CAAC,IAAD,EAAO2C,KAAP,EAAcC,GAAd,EAAmB,KAAKC,cAAxB,CAAjB;AACH;;AAEMC,YAAU,CAA2BC,KAA3B,EAAwC;AAErD,QAAIA,KAAK,GAAG,CAAR,IAAaA,KAAK,IAAI,KAAK/B,YAA/B,EAA6C;AAAE,aAAO,IAAP;AAAc;;AAE7D,QAAIgC,OAAO,GAAG,KAAKC,SAAL,KAAmB,KAAKA,SAAL,GAAiB,EAApC,CAAd;AACA,QAAIC,KAAJ,EAAuBC,KAAvB,EAAwC3C,MAAxC;;AAEA,QAAI0C,KAAK,GAAGF,OAAO,CAACD,KAAD,CAAnB,EAA4B;AAAE,aAAOG,KAAP;AAAe;;AAC7C,QAAIC,KAAK,GAAI,CAAC,KAAKxC,KAAL,CAAWM,QAAX,IAAuB,EAAxB,EAA4B8B,KAA5B,CAAb,EAA8D;AAC1DvC,YAAM,GAAG,KAAKI,OAAL,CACJwB,GADI,CACCgB,MAAD,IAAYA,MAAM,CAACN,UAAP,CAAqBC,KAArB,CADZ,EAEJM,MAFI,CAEIC,GAAD,IAA2BA,GAAG,IAAI,IAFrC,CAAT;;AAGA,UAAI9C,MAAM,CAACO,MAAP,GAAgB,CAApB,EAAuB;AACnB,eAAQiC,OAAO,CAACD,KAAD,CAAP,GAAiB,IAAI1C,OAAJ,CAAe8C,KAAK,CAAC5C,IAArB,EAA2BC,MAA3B,CAAzB;AACH;AACJ;;AAED,WAAO,IAAP;AACH;;AAIM+C,QAAM,CAA2CR,KAA3C,EAA0DS,IAA1D,EAAkE;AAC3E,QAAIC,GAAG,GAAGV,KAAV,CAD2E,CAE3E;;AACA,QAAItC,OAAO,GAAG,KAAKI,aAAnB;AAAA,QAAkC6C,GAAG,GAAGjD,OAAO,CAACM,MAAR,GAAiB,CAAzD,CAH2E,CAI3E;;AACA,QAAI0C,GAAG,GAAG,CAAV,EAAyB;AAAE,aAAO,IAAP;AAAc;;AACzC,QAAIA,GAAG,IAAIhD,OAAO,CAACiD,GAAD,CAAlB,EAAyB;AAAE,aAAO,IAAP;AAAc;;AACzC,QAAIA,GAAG,IAAI,CAAX,EAAyB;AAAE,aAAOF,IAAI,GAAGA,IAAI,CAAC,IAAD,EAAO,CAAP,EAAUC,GAAV,CAAP,GAAwB,CAAC,CAAD,EAAIA,GAAJ,CAAnC;AAA8C;;AACzE,QAAIE,GAAG,GAAG,CAAV;AAAA,QAAaC,GAAG,GAAG,CAAnB;AAAA,QAAsBC,GAAG,GAAG,CAA5B;;AACA,OAAG;AACC,UAAIF,GAAG,GAAG,CAAN,KAAYD,GAAhB,EAAqB;AACjB,eAAOF,IAAI,GAAGA,IAAI,CAAC,IAAD,EAAOG,GAAP,EAAYF,GAAG,GAAGG,GAAlB,CAAP,GAAgC,CAACD,GAAD,EAAMF,GAAG,GAAGG,GAAZ,CAA3C;AACH;;AACDC,SAAG,GAAGF,GAAG,GAAI,CAACD,GAAG,GAAGC,GAAP,IAAc,CAArB,GAA0B,CAAhC;AACAF,SAAG,IAAIhD,OAAO,CAACoD,GAAD,CAAd,GAAuBF,GAAG,GAAGE,GAA7B,GAAqCH,GAAG,GAAGG,GAA3C;AACH,KAND,QAMSJ,GAAG,GAAGhD,OAAO,CAACiD,GAAD,CAAb,IAAsBD,GAAG,KAAKG,GAAG,GAAGnD,OAAO,CAACkD,GAAD,CAAlB,CANlC;;AAOA,WAAO,IAAP;AACH;;AAEMG,SAAO,CAACf,KAAD,EAAc;AACxB,WAAO,CAAC,CAAC,KAAKQ,MAAL,CAAYR,KAAZ,EAAmB,KAAKgB,eAAxB,CAAT;AACH;;AAEMC,KAAG,CAACjB,KAAD,EAAc;AACpB,WAAO,KAAKQ,MAAL,CAAYR,KAAZ,EAAmB,KAAKkB,WAAxB,CAAP;AACH;;AAEMC,KAAG,CAACnB,KAAD,EAAgBoB,KAAhB,EAAyC;AAC/C,SAAKZ,MAAL,CAAYR,KAAZ,EAAmB,QAAaqB,CAAb,EAAgBC,CAAhB;AAAA,UAAC;AAAE7D;AAAF,OAAD;AAAA,aAAsBA,MAAM,CAAC4D,CAAD,CAAN,CAAUF,GAAV,CAAcG,CAAd,EAAiBF,KAAjB,CAAtB;AAAA,KAAnB;AACH;;AAEMG,SAAO,CAACC,OAAD,EAAuBC,MAAvB,EAAsC;AAChD,QAAIA,MAAM,IAAI,OAAOA,MAAP,KAAkB,QAAhC,EAA0C;AACtC,aAAO,KAAKjB,MAAL,CAAYiB,MAAZ,EAAoB,CAACC,IAAD,EAAOL,CAAP,EAAUC,CAAV,KAAgB,KAAKK,eAAL,CAAqBD,IAArB,EAA2BL,CAA3B,EAA8BC,CAA9B,EAAiCE,OAAjC,CAApC,CAAP;AACH;;AACD,WAAO,KAAKG,eAAL,CAAqB,IAArB,EAA2B,CAA3B,EAA8BC,IAAI,CAACC,GAAL,CAAS,CAAT,EAAYJ,MAAM,IAAI,CAAtB,CAA9B,EAAwDD,OAAxD,CAAP;AACH;;AAEMM,SAAO;AACV,UAAM;AAAErE;AAAF,QAAa,IAAnB;AACA,UAAMsE,CAAC,GAAGtE,MAAM,CAACO,MAAjB;AACA,QAAIS,SAAS,GAAQ,KAAKb,KAAL,CAAWa,SAAhC;;AACA,QAAIsD,CAAC,IAAI,CAAT,EAAY;AAAE,aAAO,IAAItD,SAAJ,CAAc,CAAd,CAAP;AAA0B;;AACxC,QAAIsD,CAAC,IAAI,CAAT,EAAY;AAAE,aAAOtE,MAAM,CAAC,CAAD,CAAN,CAAUqE,OAAV,EAAP;AAA6B;;AAC3C,QAAIE,GAAG,GAAG,CAAV;AAAA,QAAaC,GAAG,GAAG,IAAIC,KAAJ,CAAUH,CAAV,CAAnB;;AACA,SAAK,IAAIV,CAAC,GAAG,CAAC,CAAd,EAAiB,EAAEA,CAAF,GAAMU,CAAvB,GAA2B;AACvBC,SAAG,IAAI,CAACC,GAAG,CAACZ,CAAD,CAAH,GAAS5D,MAAM,CAAC4D,CAAD,CAAN,CAAUS,OAAV,EAAV,EAA+B9D,MAAtC;AACH;;AACD,QAAIS,SAAS,KAAKwD,GAAG,CAAC,CAAD,CAAH,CAAO1E,WAAzB,EAAsC;AAClCkB,eAAS,GAAGwD,GAAG,CAAC,CAAD,CAAH,CAAO1E,WAAnB;AACH;;AACD,QAAI4E,GAAG,GAAG,IAAI1D,SAAJ,CAAcuD,GAAd,CAAV;AACA,QAAIb,GAAG,GAAQ1C,SAAS,KAAKyD,KAAd,GAAsBE,QAAtB,GAAiCC,QAAhD;;AACA,SAAK,IAAIhB,CAAC,GAAG,CAAC,CAAT,EAAYX,GAAG,GAAG,CAAvB,EAA0B,EAAEW,CAAF,GAAMU,CAAhC,GAAoC;AAChCrB,SAAG,GAAGS,GAAG,CAACc,GAAG,CAACZ,CAAD,CAAJ,EAASc,GAAT,EAAczB,GAAd,CAAT;AACH;;AACD,WAAOyB,GAAP;AACH;;AAESjB,aAAW,QAA0BG,CAA1B,EAAqCC,CAArC,EAA8C;AAAA,QAA7C;AAAEzD;AAAF,KAA6C;AAAI,WAAOA,OAAO,CAACwD,CAAD,CAAP,CAAWJ,GAAX,CAAeK,CAAf,CAAP;AAA2B;;AACxFN,iBAAe,QAA0BK,CAA1B,EAAqCC,CAArC,EAA8C;AAAA,QAA7C;AAAEzD;AAAF,KAA6C;AAAI,WAAOA,OAAO,CAACwD,CAAD,CAAP,CAAWN,OAAX,CAAmBO,CAAnB,CAAP;AAA+B;;AAChGK,iBAAe,QAA0BW,UAA1B,EAA8CC,SAA9C,EAAiEf,OAAjE,EAAqF;AAAA,QAApF;AAAE3D;AAAF,KAAoF;AAC1G,QAAIwD,CAAC,GAAGiB,UAAU,GAAG,CAArB;AAAA,QAAwBP,CAAC,GAAGlE,OAAO,CAACG,MAApC;AACA,QAAIwE,KAAK,GAAGD,SAAZ;AAAA,QAAuBd,MAAM,GAAG,CAAhC;AAAA,QAAmCgB,KAAK,GAAG,CAAC,CAA5C;;AACA,WAAO,EAAEpB,CAAF,GAAMU,CAAb,EAAgB;AACZ,UAAI,EAAEU,KAAK,GAAG5E,OAAO,CAACwD,CAAD,CAAP,CAAWE,OAAX,CAAmBC,OAAnB,EAA4BgB,KAA5B,CAAV,CAAJ,EAAmD;AAC/C,eAAOf,MAAM,GAAGgB,KAAhB;AACH;;AACDD,WAAK,GAAG,CAAR;AACAf,YAAM,IAAI5D,OAAO,CAACwD,CAAD,CAAP,CAAWrD,MAArB;AACH;;AACD,WAAO,CAAC,CAAR;AACH;;AAES8B,gBAAc,CAAC4B,IAAD,EAAmB9B,KAAnB,EAAkCC,GAAlC,EAA6C;AACjE,UAAM6C,MAAM,GAAgB,EAA5B;AACA,UAAM;AAAEjF,YAAF;AAAUK,mBAAa,EAAE6E;AAAzB,QAA0CjB,IAAhD;;AACA,SAAK,IAAIL,CAAC,GAAG,CAAC,CAAT,EAAYU,CAAC,GAAGtE,MAAM,CAACO,MAA5B,EAAoC,EAAEqD,CAAF,GAAMU,CAA1C,GAA8C;AAC1C,YAAMjD,KAAK,GAAGrB,MAAM,CAAC4D,CAAD,CAApB;AACA,YAAMuB,WAAW,GAAG9D,KAAK,CAACd,MAA1B;AACA,YAAM6E,WAAW,GAAGF,YAAY,CAACtB,CAAD,CAAhC,CAH0C,CAI1C;;AACA,UAAIwB,WAAW,IAAIhD,GAAnB,EAAwB;AAAE;AAAQ,OALQ,CAM1C;;;AACA,UAAID,KAAK,IAAIiD,WAAW,GAAGD,WAA3B,EAAwC;AAAE;AAAW,OAPX,CAQ1C;;;AACA,UAAIC,WAAW,IAAIjD,KAAf,IAAyBiD,WAAW,GAAGD,WAAf,IAA+B/C,GAA3D,EAAgE;AAC5D6C,cAAM,CAACI,IAAP,CAAYhE,KAAZ;AACA;AACH,OAZyC,CAa1C;;;AACA,YAAMiE,IAAI,GAAGnB,IAAI,CAACC,GAAL,CAAS,CAAT,EAAYjC,KAAK,GAAGiD,WAApB,CAAb;AACA,YAAMG,EAAE,GAAGpB,IAAI,CAACqB,GAAL,CAASpD,GAAG,GAAGgD,WAAf,EAA4BD,WAA5B,CAAX;AACAF,YAAM,CAACI,IAAP,CAAYhE,KAAK,CAACa,KAAN,CAAYoD,IAAZ,EAAkBC,EAAlB,CAAZ;AACH;;AACD,WAAOtB,IAAI,CAACjC,KAAL,CAAWiD,MAAX,CAAP;AACH;;AApNwB;AAuN7B;;AACA,SAAS/E,gBAAT,CAA8CS,OAA9C,EAAkE;AAC9D,MAAIV,OAAO,GAAG,IAAIwF,WAAJ,CAAgB,CAAC9E,OAAO,IAAI,EAAZ,EAAgBJ,MAAhB,GAAyB,CAAzC,CAAd;AACA,MAAIyD,MAAM,GAAG/D,OAAO,CAAC,CAAD,CAAP,GAAa,CAA1B;AAAA,MAA6BM,MAAM,GAAGN,OAAO,CAACM,MAA9C;;AACA,OAAK,IAAIgC,KAAK,GAAG,CAAjB,EAAoB,EAAEA,KAAF,GAAUhC,MAA9B,GAAuC;AACnCN,WAAO,CAACsC,KAAD,CAAP,GAAkByB,MAAM,IAAIrD,OAAO,CAAC4B,KAAK,GAAG,CAAT,CAAP,CAAmBhC,MAA/C;AACH;;AACD,SAAON,OAAP;AACH;AAED;;;AACA,MAAM2E,QAAQ,GAAG,CAACJ,GAAD,EAAkBE,GAAlB,EAAmCV,MAAnC,KAAqD;AAClEU,KAAG,CAAChB,GAAJ,CAAQc,GAAR,EAAaR,MAAb;AACA,SAAQA,MAAM,GAAGQ,GAAG,CAACjE,MAArB;AACH,CAHD;AAKA;;;AACA,MAAMoE,QAAQ,GAAG,CAACH,GAAD,EAAaE,GAAb,EAAyBV,MAAzB,KAA2C;AACxD,MAAIf,GAAG,GAAGe,MAAV;;AACA,OAAK,IAAIJ,CAAC,GAAG,CAAC,CAAT,EAAYU,CAAC,GAAGE,GAAG,CAACjE,MAAzB,EAAiC,EAAEqD,CAAF,GAAMU,CAAvC,GAA2C;AACvCI,OAAG,CAACzB,GAAG,EAAJ,CAAH,GAAauB,GAAG,CAACZ,CAAD,CAAhB;AACH;;AACD,SAAOX,GAAP;AACH,CAND","names":["clampRange","DataType","selectChunkArgs","AbstractVector","Vector","Chunked","constructor","type","chunks","offsets","calculateOffsets","_type","_chunks","_chunkOffsets","_length","length","_numChildren","children","flatten","vectors","concat","typeId","VectorName","data","ArrayType","numChildren","stride","byteLength","reduce","chunk","nullCount","_nullCount","x","indices","isDictionary","_indices","map","dictionary","Symbol","iterator","clone","others","slice","begin","end","_sliceInternal","getChildAt","index","columns","_children","child","field","vector","filter","vec","search","then","idx","rhs","lhs","pos","mid","isValid","isValidInternal","get","getInternal","set","value","i","j","indexOf","element","offset","self","indexOfInternal","Math","max","toArray","n","len","src","Array","dst","arraySet","typedSet","chunkIndex","fromIndex","start","found","slices","chunkOffsets","chunkLength","chunkOffset","push","from","to","min","Uint32Array"],"sources":["vector/chunked.ts"],"sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Data } from '../data';\nimport { Field } from '../schema';\nimport { clampRange } from '../util/vector';\nimport { DataType, Dictionary } from '../type';\nimport { selectChunkArgs } from '../util/args';\nimport { DictionaryVector } from './dictionary';\nimport { AbstractVector, Vector } from '../vector';\nimport { Clonable, Sliceable, Applicative } from '../vector';\n\n/** @ignore */\ntype ChunkedDict<T extends DataType> = T extends Dictionary ? Vector<T['dictionary']> : null | never;\n/** @ignore */\ntype ChunkedKeys<T extends DataType> = T extends Dictionary ? Vector<T['indices']> | Chunked<T['indices']> : null | never;\n\n/** @ignore */\nexport type SearchContinuation<T extends Chunked> = (column: T, chunkIndex: number, valueIndex: number) => any;\n\n/** @ignore */\nexport class Chunked<T extends DataType = any>\n    extends AbstractVector<T>\n    implements Clonable<Chunked<T>>,\n               Sliceable<Chunked<T>>,\n               Applicative<T, Chunked<T>> {\n\n    /** @nocollapse */\n    public static flatten<T extends DataType>(...vectors: (Vector<T> | Vector<T>[])[]) {\n        return selectChunkArgs<Vector<T>>(Vector, vectors);\n    }\n\n    /** @nocollapse */\n    public static concat<T extends DataType>(...vectors: (Vector<T> | Vector<T>[])[]) {\n        const chunks = Chunked.flatten<T>(...vectors);\n        return new Chunked<T>(chunks[0].type, chunks);\n    }\n\n    protected _type: T;\n    protected _length: number;\n    protected _chunks: Vector<T>[];\n    protected _numChildren: number;\n    protected _children?: Chunked[];\n    protected _nullCount: number = -1;\n    protected _chunkOffsets: Uint32Array;\n\n    constructor(type: T, chunks: Vector<T>[] = [], offsets = calculateOffsets(chunks)) {\n        super();\n        this._type = type;\n        this._chunks = chunks;\n        this._chunkOffsets = offsets;\n        this._length = offsets[offsets.length - 1];\n        this._numChildren = (this._type.children || []).length;\n    }\n\n    public get type() { return this._type; }\n    public get length() { return this._length; }\n    public get chunks() { return this._chunks; }\n    public get typeId(): T['TType'] { return this._type.typeId; }\n    public get VectorName() { return `Chunked<${this._type}>`; }\n    public get data(): Data<T> {\n        return this._chunks[0] ? this._chunks[0].data : <any> null;\n    }\n\n    public get ArrayType() { return this._type.ArrayType; }\n    public get numChildren() { return this._numChildren; }\n    public get stride() { return this._chunks[0] ? this._chunks[0].stride : 1; }\n    public get byteLength(): number {\n        return this._chunks.reduce((byteLength, chunk) => byteLength + chunk.byteLength, 0);\n    }\n    public get nullCount() {\n        let nullCount = this._nullCount;\n        if (nullCount < 0) {\n            this._nullCount = nullCount = this._chunks.reduce((x, { nullCount }) => x + nullCount, 0);\n        }\n        return nullCount;\n    }\n\n    protected _indices?: ChunkedKeys<T>;\n    public get indices(): ChunkedKeys<T> | null {\n        if (DataType.isDictionary(this._type)) {\n            if (!this._indices) {\n                const chunks = (<any> this._chunks) as DictionaryVector<T, any>[];\n                this._indices = (chunks.length === 1\n                    ? chunks[0].indices\n                    : Chunked.concat(...chunks.map((x) => x.indices))) as ChunkedKeys<T>;\n            }\n            return this._indices;\n        }\n        return null;\n    }\n    public get dictionary(): ChunkedDict<T> | null {\n        if (DataType.isDictionary(this._type)) {\n            return this._chunks[this._chunks.length - 1].data.dictionary as ChunkedDict<T>;\n        }\n        return null;\n    }\n\n    public *[Symbol.iterator](): IterableIterator<T['TValue'] | null> {\n        for (const chunk of this._chunks) {\n            yield* chunk;\n        }\n    }\n\n    public clone(chunks = this._chunks): Chunked<T> {\n        return new Chunked(this._type, chunks);\n    }\n\n    public concat(...others: Vector<T>[]): Chunked<T> {\n        return this.clone(Chunked.flatten(this, ...others));\n    }\n\n    public slice(begin?: number, end?: number): Chunked<T> {\n        return clampRange(this, begin, end, this._sliceInternal);\n    }\n\n    public getChildAt<R extends DataType = any>(index: number): Chunked<R> | null {\n\n        if (index < 0 || index >= this._numChildren) { return null; }\n\n        let columns = this._children || (this._children = []);\n        let child: Chunked<R>, field: Field<R>, chunks: Vector<R>[];\n\n        if (child = columns[index]) { return child; }\n        if (field = ((this._type.children || [])[index] as Field<R>)) {\n            chunks = this._chunks\n                .map((vector) => vector.getChildAt<R>(index))\n                .filter((vec): vec is Vector<R> => vec != null);\n            if (chunks.length > 0) {\n                return (columns[index] = new Chunked<R>(field.type, chunks));\n            }\n        }\n\n        return null;\n    }\n\n    public search(index: number): [number, number] | null;\n    public search<N extends SearchContinuation<Chunked<T>>>(index: number, then?: N): ReturnType<N>;\n    public search<N extends SearchContinuation<Chunked<T>>>(index: number, then?: N) {\n        let idx = index;\n        // binary search to find the child vector and value indices\n        let offsets = this._chunkOffsets, rhs = offsets.length - 1;\n        // return early if out of bounds, or if there's just one child\n        if (idx < 0            ) { return null; }\n        if (idx >= offsets[rhs]) { return null; }\n        if (rhs <= 1           ) { return then ? then(this, 0, idx) : [0, idx]; }\n        let lhs = 0, pos = 0, mid = 0;\n        do {\n            if (lhs + 1 === rhs) {\n                return then ? then(this, lhs, idx - pos) : [lhs, idx - pos];\n            }\n            mid = lhs + ((rhs - lhs) / 2) | 0;\n            idx >= offsets[mid] ? (lhs = mid) : (rhs = mid);\n        } while (idx < offsets[rhs] && idx >= (pos = offsets[lhs]));\n        return null;\n    }\n\n    public isValid(index: number): boolean {\n        return !!this.search(index, this.isValidInternal);\n    }\n\n    public get(index: number): T['TValue'] | null {\n        return this.search(index, this.getInternal);\n    }\n\n    public set(index: number, value: T['TValue'] | null): void {\n        this.search(index, ({ chunks }, i, j) => chunks[i].set(j, value));\n    }\n\n    public indexOf(element: T['TValue'], offset?: number): number {\n        if (offset && typeof offset === 'number') {\n            return this.search(offset, (self, i, j) => this.indexOfInternal(self, i, j, element))!;\n        }\n        return this.indexOfInternal(this, 0, Math.max(0, offset || 0), element);\n    }\n\n    public toArray(): T['TArray'] {\n        const { chunks } = this;\n        const n = chunks.length;\n        let ArrayType: any = this._type.ArrayType;\n        if (n <= 0) { return new ArrayType(0); }\n        if (n <= 1) { return chunks[0].toArray(); }\n        let len = 0, src = new Array(n);\n        for (let i = -1; ++i < n;) {\n            len += (src[i] = chunks[i].toArray()).length;\n        }\n        if (ArrayType !== src[0].constructor) {\n            ArrayType = src[0].constructor;\n        }\n        let dst = new ArrayType(len);\n        let set: any = ArrayType === Array ? arraySet : typedSet;\n        for (let i = -1, idx = 0; ++i < n;) {\n            idx = set(src[i], dst, idx);\n        }\n        return dst;\n    }\n\n    protected getInternal({ _chunks }: Chunked<T>, i: number, j: number) { return _chunks[i].get(j); }\n    protected isValidInternal({ _chunks }: Chunked<T>, i: number, j: number) { return _chunks[i].isValid(j); }\n    protected indexOfInternal({ _chunks }: Chunked<T>, chunkIndex: number, fromIndex: number, element: T['TValue']) {\n        let i = chunkIndex - 1, n = _chunks.length;\n        let start = fromIndex, offset = 0, found = -1;\n        while (++i < n) {\n            if (~(found = _chunks[i].indexOf(element, start))) {\n                return offset + found;\n            }\n            start = 0;\n            offset += _chunks[i].length;\n        }\n        return -1;\n    }\n\n    protected _sliceInternal(self: Chunked<T>, begin: number, end: number) {\n        const slices: Vector<T>[] = [];\n        const { chunks, _chunkOffsets: chunkOffsets } = self;\n        for (let i = -1, n = chunks.length; ++i < n;) {\n            const chunk = chunks[i];\n            const chunkLength = chunk.length;\n            const chunkOffset = chunkOffsets[i];\n            // If the child is to the right of the slice boundary, we can stop\n            if (chunkOffset >= end) { break; }\n            // If the child is to the left of of the slice boundary, exclude\n            if (begin >= chunkOffset + chunkLength) { continue; }\n            // If the child is between both left and right boundaries, include w/o slicing\n            if (chunkOffset >= begin && (chunkOffset + chunkLength) <= end) {\n                slices.push(chunk);\n                continue;\n            }\n            // If the child overlaps one of the slice boundaries, include that slice\n            const from = Math.max(0, begin - chunkOffset);\n            const to = Math.min(end - chunkOffset, chunkLength);\n            slices.push(chunk.slice(from, to) as Vector<T>);\n        }\n        return self.clone(slices);\n    }\n}\n\n/** @ignore */\nfunction calculateOffsets<T extends DataType>(vectors: Vector<T>[]) {\n    let offsets = new Uint32Array((vectors || []).length + 1);\n    let offset = offsets[0] = 0, length = offsets.length;\n    for (let index = 0; ++index < length;) {\n        offsets[index] = (offset += vectors[index - 1].length);\n    }\n    return offsets;\n}\n\n/** @ignore */\nconst typedSet = (src: TypedArray, dst: TypedArray, offset: number) => {\n    dst.set(src, offset);\n    return (offset + src.length);\n};\n\n/** @ignore */\nconst arraySet = (src: any[], dst: any[], offset: number) => {\n    let idx = offset;\n    for (let i = -1, n = src.length; ++i < n;) {\n        dst[idx++] = src[i];\n    }\n    return idx;\n};\n\n/** @ignore */\ninterface TypedArray extends ArrayBufferView {\n    readonly length: number;\n    readonly [n: number]: number;\n    set(array: ArrayLike<number>, offset?: number): void;\n}\n"]},"metadata":{},"sourceType":"module"}