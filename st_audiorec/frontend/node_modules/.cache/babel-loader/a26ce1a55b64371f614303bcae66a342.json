{"ast":null,"code":"// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { Schema, Field } from '../../schema';\nimport { Dictionary, Utf8, Binary, Decimal, FixedSizeBinary, List, FixedSizeList, Map_, Struct, Union, Bool, Null, Int, Float, Date_, Time, Interval, Timestamp, Int32 } from '../../type';\nimport { DictionaryBatch, RecordBatch, FieldNode, BufferRegion } from './message';\nimport { TimeUnit, Precision, IntervalUnit, UnionMode, DateUnit } from '../../enum';\n/** @ignore */\n\nexport function schemaFromJSON(_schema) {\n  let dictionaries = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : new Map();\n  return new Schema(schemaFieldsFromJSON(_schema, dictionaries), customMetadataFromJSON(_schema['customMetadata']), dictionaries);\n}\n/** @ignore */\n\nexport function recordBatchFromJSON(b) {\n  return new RecordBatch(b['count'], fieldNodesFromJSON(b['columns']), buffersFromJSON(b['columns']));\n}\n/** @ignore */\n\nexport function dictionaryBatchFromJSON(b) {\n  return new DictionaryBatch(recordBatchFromJSON(b['data']), b['id'], b['isDelta']);\n}\n/** @ignore */\n\nfunction schemaFieldsFromJSON(_schema, dictionaries) {\n  return (_schema['fields'] || []).filter(Boolean).map(f => Field.fromJSON(f, dictionaries));\n}\n/** @ignore */\n\n\nfunction fieldChildrenFromJSON(_field, dictionaries) {\n  return (_field['children'] || []).filter(Boolean).map(f => Field.fromJSON(f, dictionaries));\n}\n/** @ignore */\n\n\nfunction fieldNodesFromJSON(xs) {\n  return (xs || []).reduce((fieldNodes, column) => [...fieldNodes, new FieldNode(column['count'], nullCountFromJSON(column['VALIDITY'])), ...fieldNodesFromJSON(column['children'])], []);\n}\n/** @ignore */\n\n\nfunction buffersFromJSON(xs) {\n  let buffers = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n\n  for (let i = -1, n = (xs || []).length; ++i < n;) {\n    const column = xs[i];\n    column['VALIDITY'] && buffers.push(new BufferRegion(buffers.length, column['VALIDITY'].length));\n    column['TYPE'] && buffers.push(new BufferRegion(buffers.length, column['TYPE'].length));\n    column['OFFSET'] && buffers.push(new BufferRegion(buffers.length, column['OFFSET'].length));\n    column['DATA'] && buffers.push(new BufferRegion(buffers.length, column['DATA'].length));\n    buffers = buffersFromJSON(column['children'], buffers);\n  }\n\n  return buffers;\n}\n/** @ignore */\n\n\nfunction nullCountFromJSON(validity) {\n  return (validity || []).reduce((sum, val) => sum + +(val === 0), 0);\n}\n/** @ignore */\n\n\nexport function fieldFromJSON(_field, dictionaries) {\n  let id;\n  let keys;\n  let field;\n  let dictMeta;\n  let type;\n  let dictType; // If no dictionary encoding\n\n  if (!dictionaries || !(dictMeta = _field['dictionary'])) {\n    type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries));\n    field = new Field(_field['name'], type, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  } // tslint:disable\n  // If dictionary encoded and the first time we've seen this dictionary id, decode\n  // the data type and child fields, then wrap in a Dictionary type and insert the\n  // data type into the dictionary types map.\n  else if (!dictionaries.has(id = dictMeta['id'])) {\n    // a dictionary index defaults to signed 32 bit int if unspecified\n    keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) : new Int32();\n    dictionaries.set(id, type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries)));\n    dictType = new Dictionary(type, keys, id, dictMeta['isOrdered']);\n    field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  } // If dictionary encoded, and have already seen this dictionary Id in the schema, then reuse the\n  // data type and wrap in a new Dictionary type and field.\n  else {\n    // a dictionary index defaults to signed 32 bit int if unspecified\n    keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) : new Int32();\n    dictType = new Dictionary(dictionaries.get(id), keys, id, dictMeta['isOrdered']);\n    field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  }\n\n  return field || null;\n}\n/** @ignore */\n\nfunction customMetadataFromJSON(_metadata) {\n  return new Map(Object.entries(_metadata || {}));\n}\n/** @ignore */\n\n\nfunction indexTypeFromJSON(_type) {\n  return new Int(_type['isSigned'], _type['bitWidth']);\n}\n/** @ignore */\n\n\nfunction typeFromJSON(f, children) {\n  const typeId = f['type']['name'];\n\n  switch (typeId) {\n    case 'NONE':\n      return new Null();\n\n    case 'null':\n      return new Null();\n\n    case 'binary':\n      return new Binary();\n\n    case 'utf8':\n      return new Utf8();\n\n    case 'bool':\n      return new Bool();\n\n    case 'list':\n      return new List((children || [])[0]);\n\n    case 'struct':\n      return new Struct(children || []);\n\n    case 'struct_':\n      return new Struct(children || []);\n  }\n\n  switch (typeId) {\n    case 'int':\n      {\n        const t = f['type'];\n        return new Int(t['isSigned'], t['bitWidth']);\n      }\n\n    case 'floatingpoint':\n      {\n        const t = f['type'];\n        return new Float(Precision[t['precision']]);\n      }\n\n    case 'decimal':\n      {\n        const t = f['type'];\n        return new Decimal(t['scale'], t['precision']);\n      }\n\n    case 'date':\n      {\n        const t = f['type'];\n        return new Date_(DateUnit[t['unit']]);\n      }\n\n    case 'time':\n      {\n        const t = f['type'];\n        return new Time(TimeUnit[t['unit']], t['bitWidth']);\n      }\n\n    case 'timestamp':\n      {\n        const t = f['type'];\n        return new Timestamp(TimeUnit[t['unit']], t['timezone']);\n      }\n\n    case 'interval':\n      {\n        const t = f['type'];\n        return new Interval(IntervalUnit[t['unit']]);\n      }\n\n    case 'union':\n      {\n        const t = f['type'];\n        return new Union(UnionMode[t['mode']], t['typeIds'] || [], children || []);\n      }\n\n    case 'fixedsizebinary':\n      {\n        const t = f['type'];\n        return new FixedSizeBinary(t['byteWidth']);\n      }\n\n    case 'fixedsizelist':\n      {\n        const t = f['type'];\n        return new FixedSizeList(t['listSize'], (children || [])[0]);\n      }\n\n    case 'map':\n      {\n        const t = f['type'];\n        return new Map_((children || [])[0], t['keysSorted']);\n      }\n  }\n\n  throw new Error(`Unrecognized type: \"${typeId}\"`);\n}","map":{"version":3,"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAASA,MAAT,EAAiBC,KAAjB,QAA8B,cAA9B;AACA,SACcC,UADd,EAEIC,IAFJ,EAEUC,MAFV,EAEkBC,OAFlB,EAE2BC,eAF3B,EAGIC,IAHJ,EAGUC,aAHV,EAGyBC,IAHzB,EAG+BC,MAH/B,EAGuCC,KAHvC,EAIIC,IAJJ,EAIUC,IAJV,EAIgBC,GAJhB,EAIqBC,KAJrB,EAI4BC,KAJ5B,EAImCC,IAJnC,EAIyCC,QAJzC,EAImDC,SAJnD,EAI2EC,KAJ3E,QAKO,YALP;AAOA,SAASC,eAAT,EAA0BC,WAA1B,EAAuCC,SAAvC,EAAkDC,YAAlD,QAAsE,WAAtE;AACA,SAASC,QAAT,EAAmBC,SAAnB,EAA8BC,YAA9B,EAA4CC,SAA5C,EAAuDC,QAAvD,QAAuE,YAAvE;AAEA;;AACA,OAAM,SAAUC,cAAV,CAAyBC,OAAzB,EAAsF;AAAA,MAA/CC,YAA+C,uEAAT,IAAIC,GAAJ,EAAS;AACxF,SAAO,IAAIjC,MAAJ,CACHkC,oBAAoB,CAACH,OAAD,EAAUC,YAAV,CADjB,EAEHG,sBAAsB,CAACJ,OAAO,CAAC,gBAAD,CAAR,CAFnB,EAGHC,YAHG,CAAP;AAKH;AAED;;AACA,OAAM,SAAUI,mBAAV,CAA8BC,CAA9B,EAAoC;AACtC,SAAO,IAAIf,WAAJ,CACHe,CAAC,CAAC,OAAD,CADE,EAEHC,kBAAkB,CAACD,CAAC,CAAC,SAAD,CAAF,CAFf,EAGHE,eAAe,CAACF,CAAC,CAAC,SAAD,CAAF,CAHZ,CAAP;AAKH;AAED;;AACA,OAAM,SAAUG,uBAAV,CAAkCH,CAAlC,EAAwC;AAC1C,SAAO,IAAIhB,eAAJ,CACHe,mBAAmB,CAACC,CAAC,CAAC,MAAD,CAAF,CADhB,EAEHA,CAAC,CAAC,IAAD,CAFE,EAEMA,CAAC,CAAC,SAAD,CAFP,CAAP;AAIH;AAED;;AACA,SAASH,oBAAT,CAA8BH,OAA9B,EAA4CC,YAA5C,EAAgF;AAC5E,SAAO,CAACD,OAAO,CAAC,QAAD,CAAP,IAAqB,EAAtB,EAA0BU,MAA1B,CAAiCC,OAAjC,EAA0CC,GAA1C,CAA+CC,CAAD,IAAY3C,KAAK,CAAC4C,QAAN,CAAeD,CAAf,EAAkBZ,YAAlB,CAA1D,CAAP;AACH;AAED;;;AACA,SAASc,qBAAT,CAA+BC,MAA/B,EAA4Cf,YAA5C,EAAgF;AAC5E,SAAO,CAACe,MAAM,CAAC,UAAD,CAAN,IAAsB,EAAvB,EAA2BN,MAA3B,CAAkCC,OAAlC,EAA2CC,GAA3C,CAAgDC,CAAD,IAAY3C,KAAK,CAAC4C,QAAN,CAAeD,CAAf,EAAkBZ,YAAlB,CAA3D,CAAP;AACH;AAED;;;AACA,SAASM,kBAAT,CAA4BU,EAA5B,EAAqC;AACjC,SAAO,CAACA,EAAE,IAAI,EAAP,EAAWC,MAAX,CAA+B,CAACC,UAAD,EAAaC,MAAb,KAA6B,CAC/D,GAAGD,UAD4D,EAE/D,IAAI3B,SAAJ,CACI4B,MAAM,CAAC,OAAD,CADV,EAEIC,iBAAiB,CAACD,MAAM,CAAC,UAAD,CAAP,CAFrB,CAF+D,EAM/D,GAAGb,kBAAkB,CAACa,MAAM,CAAC,UAAD,CAAP,CAN0C,CAA5D,EAOJ,EAPI,CAAP;AAQH;AAED;;;AACA,SAASZ,eAAT,CAAyBS,EAAzB,EAAgE;AAAA,MAA5BK,OAA4B,uEAAF,EAAE;;AAC5D,OAAK,IAAIC,CAAC,GAAG,CAAC,CAAT,EAAYC,CAAC,GAAG,CAACP,EAAE,IAAI,EAAP,EAAWQ,MAAhC,EAAwC,EAAEF,CAAF,GAAMC,CAA9C,GAAkD;AAC9C,UAAMJ,MAAM,GAAGH,EAAE,CAACM,CAAD,CAAjB;AACAH,UAAM,CAAC,UAAD,CAAN,IAAsBE,OAAO,CAACI,IAAR,CAAa,IAAIjC,YAAJ,CAAiB6B,OAAO,CAACG,MAAzB,EAAiCL,MAAM,CAAC,UAAD,CAAN,CAAmBK,MAApD,CAAb,CAAtB;AACAL,UAAM,CAAC,MAAD,CAAN,IAAkBE,OAAO,CAACI,IAAR,CAAa,IAAIjC,YAAJ,CAAiB6B,OAAO,CAACG,MAAzB,EAAiCL,MAAM,CAAC,MAAD,CAAN,CAAeK,MAAhD,CAAb,CAAlB;AACAL,UAAM,CAAC,QAAD,CAAN,IAAoBE,OAAO,CAACI,IAAR,CAAa,IAAIjC,YAAJ,CAAiB6B,OAAO,CAACG,MAAzB,EAAiCL,MAAM,CAAC,QAAD,CAAN,CAAiBK,MAAlD,CAAb,CAApB;AACAL,UAAM,CAAC,MAAD,CAAN,IAAkBE,OAAO,CAACI,IAAR,CAAa,IAAIjC,YAAJ,CAAiB6B,OAAO,CAACG,MAAzB,EAAiCL,MAAM,CAAC,MAAD,CAAN,CAAeK,MAAhD,CAAb,CAAlB;AACAH,WAAO,GAAGd,eAAe,CAACY,MAAM,CAAC,UAAD,CAAP,EAAqBE,OAArB,CAAzB;AACH;;AACD,SAAOA,OAAP;AACH;AAED;;;AACA,SAASD,iBAAT,CAA2BM,QAA3B,EAA6C;AACzC,SAAO,CAACA,QAAQ,IAAI,EAAb,EAAiBT,MAAjB,CAAwB,CAACU,GAAD,EAAMC,GAAN,KAAcD,GAAG,GAAG,EAAEC,GAAG,KAAK,CAAV,CAA5C,EAA0D,CAA1D,CAAP;AACH;AAED;;;AACA,OAAM,SAAUC,aAAV,CAAwBd,MAAxB,EAAqCf,YAArC,EAAyE;AAE3E,MAAI8B,EAAJ;AACA,MAAIC,IAAJ;AACA,MAAIC,KAAJ;AACA,MAAIC,QAAJ;AACA,MAAIC,IAAJ;AACA,MAAIC,QAAJ,CAP2E,CAS3E;;AACA,MAAI,CAACnC,YAAD,IAAiB,EAAEiC,QAAQ,GAAGlB,MAAM,CAAC,YAAD,CAAnB,CAArB,EAAyD;AACrDmB,QAAI,GAAGE,YAAY,CAACrB,MAAD,EAASD,qBAAqB,CAACC,MAAD,EAASf,YAAT,CAA9B,CAAnB;AACAgC,SAAK,GAAG,IAAI/D,KAAJ,CAAU8C,MAAM,CAAC,MAAD,CAAhB,EAA0BmB,IAA1B,EAAgCnB,MAAM,CAAC,UAAD,CAAtC,EAAoDZ,sBAAsB,CAACY,MAAM,CAAC,gBAAD,CAAP,CAA1E,CAAR;AACH,GAHD,CAIA;AACA;AACA;AACA;AAPA,OAQK,IAAI,CAACf,YAAY,CAACqC,GAAb,CAAiBP,EAAE,GAAGG,QAAQ,CAAC,IAAD,CAA9B,CAAL,EAA4C;AAC7C;AACAF,QAAI,GAAG,CAACA,IAAI,GAAGE,QAAQ,CAAC,WAAD,CAAhB,IAAiCK,iBAAiB,CAACP,IAAD,CAAlD,GAAoE,IAAI3C,KAAJ,EAA3E;AACAY,gBAAY,CAACuC,GAAb,CAAiBT,EAAjB,EAAqBI,IAAI,GAAGE,YAAY,CAACrB,MAAD,EAASD,qBAAqB,CAACC,MAAD,EAASf,YAAT,CAA9B,CAAxC;AACAmC,YAAQ,GAAG,IAAIjE,UAAJ,CAAegE,IAAf,EAAqBH,IAArB,EAA2BD,EAA3B,EAA+BG,QAAQ,CAAC,WAAD,CAAvC,CAAX;AACAD,SAAK,GAAG,IAAI/D,KAAJ,CAAU8C,MAAM,CAAC,MAAD,CAAhB,EAA0BoB,QAA1B,EAAoCpB,MAAM,CAAC,UAAD,CAA1C,EAAwDZ,sBAAsB,CAACY,MAAM,CAAC,gBAAD,CAAP,CAA9E,CAAR;AACH,GANI,CAOL;AACA;AARK,OASA;AACD;AACAgB,QAAI,GAAG,CAACA,IAAI,GAAGE,QAAQ,CAAC,WAAD,CAAhB,IAAiCK,iBAAiB,CAACP,IAAD,CAAlD,GAAoE,IAAI3C,KAAJ,EAA3E;AACA+C,YAAQ,GAAG,IAAIjE,UAAJ,CAAe8B,YAAY,CAACwC,GAAb,CAAiBV,EAAjB,CAAf,EAAsCC,IAAtC,EAA4CD,EAA5C,EAAgDG,QAAQ,CAAC,WAAD,CAAxD,CAAX;AACAD,SAAK,GAAG,IAAI/D,KAAJ,CAAU8C,MAAM,CAAC,MAAD,CAAhB,EAA0BoB,QAA1B,EAAoCpB,MAAM,CAAC,UAAD,CAA1C,EAAwDZ,sBAAsB,CAACY,MAAM,CAAC,gBAAD,CAAP,CAA9E,CAAR;AACH;;AACD,SAAOiB,KAAK,IAAI,IAAhB;AACH;AAED;;AACA,SAAS7B,sBAAT,CAAgCsC,SAAhC,EAAkD;AAC9C,SAAO,IAAIxC,GAAJ,CAAwByC,MAAM,CAACC,OAAP,CAAeF,SAAS,IAAI,EAA5B,CAAxB,CAAP;AACH;AAED;;;AACA,SAASH,iBAAT,CAA2BM,KAA3B,EAAqC;AACjC,SAAO,IAAI9D,GAAJ,CAAQ8D,KAAK,CAAC,UAAD,CAAb,EAA2BA,KAAK,CAAC,UAAD,CAAhC,CAAP;AACH;AAED;;;AACA,SAASR,YAAT,CAAsBxB,CAAtB,EAA8BiC,QAA9B,EAAgD;AAE5C,QAAMC,MAAM,GAAGlC,CAAC,CAAC,MAAD,CAAD,CAAU,MAAV,CAAf;;AAEA,UAAQkC,MAAR;AACI,SAAK,MAAL;AAAe,aAAO,IAAIjE,IAAJ,EAAP;;AACf,SAAK,MAAL;AAAe,aAAO,IAAIA,IAAJ,EAAP;;AACf,SAAK,QAAL;AAAe,aAAO,IAAIT,MAAJ,EAAP;;AACf,SAAK,MAAL;AAAe,aAAO,IAAID,IAAJ,EAAP;;AACf,SAAK,MAAL;AAAe,aAAO,IAAIS,IAAJ,EAAP;;AACf,SAAK,MAAL;AAAe,aAAO,IAAIL,IAAJ,CAAS,CAACsE,QAAQ,IAAI,EAAb,EAAiB,CAAjB,CAAT,CAAP;;AACf,SAAK,QAAL;AAAe,aAAO,IAAInE,MAAJ,CAAWmE,QAAQ,IAAI,EAAvB,CAAP;;AACf,SAAK,SAAL;AAAgB,aAAO,IAAInE,MAAJ,CAAWmE,QAAQ,IAAI,EAAvB,CAAP;AARpB;;AAWA,UAAQC,MAAR;AACI,SAAK,KAAL;AAAY;AACR,cAAMC,CAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;AACA,eAAO,IAAI9B,GAAJ,CAAQiE,CAAC,CAAC,UAAD,CAAT,EAAuBA,CAAC,CAAC,UAAD,CAAxB,CAAP;AACH;;AACD,SAAK,eAAL;AAAsB;AAClB,cAAMA,CAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;AACA,eAAO,IAAI7B,KAAJ,CAAUW,SAAS,CAACqD,CAAC,CAAC,WAAD,CAAF,CAAnB,CAAP;AACH;;AACD,SAAK,SAAL;AAAgB;AACZ,cAAMA,CAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;AACA,eAAO,IAAIvC,OAAJ,CAAY0E,CAAC,CAAC,OAAD,CAAb,EAAwBA,CAAC,CAAC,WAAD,CAAzB,CAAP;AACH;;AACD,SAAK,MAAL;AAAa;AACT,cAAMA,CAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;AACA,eAAO,IAAI5B,KAAJ,CAAUa,QAAQ,CAACkD,CAAC,CAAC,MAAD,CAAF,CAAlB,CAAP;AACH;;AACD,SAAK,MAAL;AAAa;AACT,cAAMA,CAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;AACA,eAAO,IAAI3B,IAAJ,CAASQ,QAAQ,CAACsD,CAAC,CAAC,MAAD,CAAF,CAAjB,EAAqCA,CAAC,CAAC,UAAD,CAAtC,CAAP;AACH;;AACD,SAAK,WAAL;AAAkB;AACd,cAAMA,CAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;AACA,eAAO,IAAIzB,SAAJ,CAAcM,QAAQ,CAACsD,CAAC,CAAC,MAAD,CAAF,CAAtB,EAA0CA,CAAC,CAAC,UAAD,CAA3C,CAAP;AACH;;AACD,SAAK,UAAL;AAAiB;AACb,cAAMA,CAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;AACA,eAAO,IAAI1B,QAAJ,CAAaS,YAAY,CAACoD,CAAC,CAAC,MAAD,CAAF,CAAzB,CAAP;AACH;;AACD,SAAK,OAAL;AAAc;AACV,cAAMA,CAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;AACA,eAAO,IAAIjC,KAAJ,CAAUiB,SAAS,CAACmD,CAAC,CAAC,MAAD,CAAF,CAAnB,EAAwCA,CAAC,CAAC,SAAD,CAAD,IAAgB,EAAxD,EAA6DF,QAAQ,IAAI,EAAzE,CAAP;AACH;;AACD,SAAK,iBAAL;AAAwB;AACpB,cAAME,CAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;AACA,eAAO,IAAItC,eAAJ,CAAoByE,CAAC,CAAC,WAAD,CAArB,CAAP;AACH;;AACD,SAAK,eAAL;AAAsB;AAClB,cAAMA,CAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;AACA,eAAO,IAAIpC,aAAJ,CAAkBuE,CAAC,CAAC,UAAD,CAAnB,EAAiC,CAACF,QAAQ,IAAI,EAAb,EAAiB,CAAjB,CAAjC,CAAP;AACH;;AACD,SAAK,KAAL;AAAY;AACR,cAAME,CAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;AACA,eAAO,IAAInC,IAAJ,CAAS,CAACoE,QAAQ,IAAI,EAAb,EAAiB,CAAjB,CAAT,EAA8BE,CAAC,CAAC,YAAD,CAA/B,CAAP;AACH;AA5CL;;AA8CA,QAAM,IAAIC,KAAJ,CAAU,uBAAuBF,MAAM,GAAvC,CAAN;AACH","names":["Schema","Field","Dictionary","Utf8","Binary","Decimal","FixedSizeBinary","List","FixedSizeList","Map_","Struct","Union","Bool","Null","Int","Float","Date_","Time","Interval","Timestamp","Int32","DictionaryBatch","RecordBatch","FieldNode","BufferRegion","TimeUnit","Precision","IntervalUnit","UnionMode","DateUnit","schemaFromJSON","_schema","dictionaries","Map","schemaFieldsFromJSON","customMetadataFromJSON","recordBatchFromJSON","b","fieldNodesFromJSON","buffersFromJSON","dictionaryBatchFromJSON","filter","Boolean","map","f","fromJSON","fieldChildrenFromJSON","_field","xs","reduce","fieldNodes","column","nullCountFromJSON","buffers","i","n","length","push","validity","sum","val","fieldFromJSON","id","keys","field","dictMeta","type","dictType","typeFromJSON","has","indexTypeFromJSON","set","get","_metadata","Object","entries","_type","children","typeId","t","Error"],"sources":["ipc/metadata/json.ts"],"sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Schema, Field } from '../../schema';\nimport {\n    DataType, Dictionary, TimeBitWidth,\n    Utf8, Binary, Decimal, FixedSizeBinary,\n    List, FixedSizeList, Map_, Struct, Union,\n    Bool, Null, Int, Float, Date_, Time, Interval, Timestamp, IntBitWidth, Int32, TKeys,\n} from '../../type';\n\nimport { DictionaryBatch, RecordBatch, FieldNode, BufferRegion } from './message';\nimport { TimeUnit, Precision, IntervalUnit, UnionMode, DateUnit } from '../../enum';\n\n/** @ignore */\nexport function schemaFromJSON(_schema: any, dictionaries: Map<number, DataType> = new Map()) {\n    return new Schema(\n        schemaFieldsFromJSON(_schema, dictionaries),\n        customMetadataFromJSON(_schema['customMetadata']),\n        dictionaries\n    );\n}\n\n/** @ignore */\nexport function recordBatchFromJSON(b: any) {\n    return new RecordBatch(\n        b['count'],\n        fieldNodesFromJSON(b['columns']),\n        buffersFromJSON(b['columns'])\n    );\n}\n\n/** @ignore */\nexport function dictionaryBatchFromJSON(b: any) {\n    return new DictionaryBatch(\n        recordBatchFromJSON(b['data']),\n        b['id'], b['isDelta']\n    );\n}\n\n/** @ignore */\nfunction schemaFieldsFromJSON(_schema: any, dictionaries?: Map<number, DataType>) {\n    return (_schema['fields'] || []).filter(Boolean).map((f: any) => Field.fromJSON(f, dictionaries));\n}\n\n/** @ignore */\nfunction fieldChildrenFromJSON(_field: any, dictionaries?: Map<number, DataType>): Field[] {\n    return (_field['children'] || []).filter(Boolean).map((f: any) => Field.fromJSON(f, dictionaries));\n}\n\n/** @ignore */\nfunction fieldNodesFromJSON(xs: any[]): FieldNode[] {\n    return (xs || []).reduce<FieldNode[]>((fieldNodes, column: any) => [\n        ...fieldNodes,\n        new FieldNode(\n            column['count'],\n            nullCountFromJSON(column['VALIDITY'])\n        ),\n        ...fieldNodesFromJSON(column['children'])\n    ], [] as FieldNode[]);\n}\n\n/** @ignore */\nfunction buffersFromJSON(xs: any[], buffers: BufferRegion[] = []): BufferRegion[] {\n    for (let i = -1, n = (xs || []).length; ++i < n;) {\n        const column = xs[i];\n        column['VALIDITY'] && buffers.push(new BufferRegion(buffers.length, column['VALIDITY'].length));\n        column['TYPE'] && buffers.push(new BufferRegion(buffers.length, column['TYPE'].length));\n        column['OFFSET'] && buffers.push(new BufferRegion(buffers.length, column['OFFSET'].length));\n        column['DATA'] && buffers.push(new BufferRegion(buffers.length, column['DATA'].length));\n        buffers = buffersFromJSON(column['children'], buffers);\n    }\n    return buffers;\n}\n\n/** @ignore */\nfunction nullCountFromJSON(validity: number[]) {\n    return (validity || []).reduce((sum, val) => sum + +(val === 0), 0);\n}\n\n/** @ignore */\nexport function fieldFromJSON(_field: any, dictionaries?: Map<number, DataType>) {\n\n    let id: number;\n    let keys: TKeys | null;\n    let field: Field | void;\n    let dictMeta: any;\n    let type: DataType<any>;\n    let dictType: Dictionary;\n\n    // If no dictionary encoding\n    if (!dictionaries || !(dictMeta = _field['dictionary'])) {\n        type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries));\n        field = new Field(_field['name'], type, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    // tslint:disable\n    // If dictionary encoded and the first time we've seen this dictionary id, decode\n    // the data type and child fields, then wrap in a Dictionary type and insert the\n    // data type into the dictionary types map.\n    else if (!dictionaries.has(id = dictMeta['id'])) {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) as TKeys : new Int32();\n        dictionaries.set(id, type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries)));\n        dictType = new Dictionary(type, keys, id, dictMeta['isOrdered']);\n        field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    // If dictionary encoded, and have already seen this dictionary Id in the schema, then reuse the\n    // data type and wrap in a new Dictionary type and field.\n    else {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) as TKeys : new Int32();\n        dictType = new Dictionary(dictionaries.get(id)!, keys, id, dictMeta['isOrdered']);\n        field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    return field || null;\n}\n\n/** @ignore */\nfunction customMetadataFromJSON(_metadata?: object) {\n    return new Map<string, string>(Object.entries(_metadata || {}));\n}\n\n/** @ignore */\nfunction indexTypeFromJSON(_type: any) {\n    return new Int(_type['isSigned'], _type['bitWidth']);\n}\n\n/** @ignore */\nfunction typeFromJSON(f: any, children?: Field[]): DataType<any> {\n\n    const typeId = f['type']['name'];\n\n    switch (typeId) {\n        case 'NONE':   return new Null();\n        case 'null':   return new Null();\n        case 'binary': return new Binary();\n        case 'utf8':   return new Utf8();\n        case 'bool':   return new Bool();\n        case 'list':   return new List((children || [])[0]);\n        case 'struct': return new Struct(children || []);\n        case 'struct_': return new Struct(children || []);\n    }\n\n    switch (typeId) {\n        case 'int': {\n            const t = f['type'];\n            return new Int(t['isSigned'], t['bitWidth'] as IntBitWidth);\n        }\n        case 'floatingpoint': {\n            const t = f['type'];\n            return new Float(Precision[t['precision']] as any);\n        }\n        case 'decimal': {\n            const t = f['type'];\n            return new Decimal(t['scale'], t['precision']);\n        }\n        case 'date': {\n            const t = f['type'];\n            return new Date_(DateUnit[t['unit']] as any);\n        }\n        case 'time': {\n            const t = f['type'];\n            return new Time(TimeUnit[t['unit']] as any, t['bitWidth'] as TimeBitWidth);\n        }\n        case 'timestamp': {\n            const t = f['type'];\n            return new Timestamp(TimeUnit[t['unit']] as any, t['timezone']);\n        }\n        case 'interval': {\n            const t = f['type'];\n            return new Interval(IntervalUnit[t['unit']] as any);\n        }\n        case 'union': {\n            const t = f['type'];\n            return new Union(UnionMode[t['mode']] as any, (t['typeIds'] || []), children || []);\n        }\n        case 'fixedsizebinary': {\n            const t = f['type'];\n            return new FixedSizeBinary(t['byteWidth']);\n        }\n        case 'fixedsizelist': {\n            const t = f['type'];\n            return new FixedSizeList(t['listSize'], (children || [])[0]);\n        }\n        case 'map': {\n            const t = f['type'];\n            return new Map_((children || [])[0], t['keysSorted']);\n        }\n    }\n    throw new Error(`Unrecognized type: \"${typeId}\"`);\n}\n"]},"metadata":{},"sourceType":"module"}